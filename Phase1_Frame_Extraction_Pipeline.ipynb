{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a09528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration Loaded.\n",
      "   Input: C:\\UCF_video_dataset\\Raw_Videos_Unified\n",
      "   Output: C:\\UCF_video_dataset\\Processed_Clips\n",
      "   Logic: Seq=16, Stride=5, Step=64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for nicer progress bars in Jupyter\n",
    "import shutil\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION (Strictly from Thesis PDF)\n",
    "# ==========================================\n",
    "# Input: The Unified folder you organized\n",
    "SOURCE_DIR = r\"C:\\UCF_video_dataset\\Raw_Videos_Unified\"\n",
    "\n",
    "# Output: Where the clips will be saved\n",
    "OUTPUT_DIR = r\"C:\\UCF_video_dataset\\Processed_Clips\"\n",
    "\n",
    "# LOGIC PARAMETERS\n",
    "SEQ_LEN = 16        # Frames per clip (Depth)\n",
    "STRIDE = 5          # Dilation (Skip 4, take 5th)\n",
    "CLIP_STEP = 64      # Sliding Window Jump\n",
    "IMG_SIZE = 224      # Resize for TimeSformer\n",
    "\n",
    "print(\"‚úÖ Configuration Loaded.\")\n",
    "print(f\"   Input: {SOURCE_DIR}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Logic: Seq={SEQ_LEN}, Stride={STRIDE}, Step={CLIP_STEP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7a12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SYSTEM DIAGNOSTICS\n",
      "==================================================\n",
      "‚úÖ GPU DETECTED: NVIDIA GeForce RTX 3080 Ti\n",
      "   Status: Ready for Phase 2 (TimeSformer).\n",
      "   Note: Phase 1 (Frame Extraction) will use CPU/Disk mainly.\n",
      "‚úÖ DATASET FOUND: 15 Classes detected.\n",
      "   Classes: ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'Normal', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Splits', 'Stealing', 'Vandalism']\n"
     ]
    }
   ],
   "source": [
    "def check_system():\n",
    "    print(\"=\"*50)\n",
    "    print(\"SYSTEM DIAGNOSTICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check GPU\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"‚úÖ GPU DETECTED: {gpu_name}\")\n",
    "        print(\"   Status: Ready for Phase 2 (TimeSformer).\")\n",
    "        print(\"   Note: Phase 1 (Frame Extraction) will use CPU/Disk mainly.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU NOT DETECTED!\")\n",
    "        print(\"   Phase 2 will be very slow. Check your CUDA installation.\")\n",
    "        \n",
    "    # Check Source Directory\n",
    "    if not os.path.exists(SOURCE_DIR):\n",
    "        print(f\"‚ùå ERROR: Source directory not found: {SOURCE_DIR}\")\n",
    "        return False\n",
    "    \n",
    "    # Check classes\n",
    "    try:\n",
    "        classes = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "        print(f\"‚úÖ DATASET FOUND: {len(classes)} Classes detected.\")\n",
    "        print(f\"   Classes: {classes}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR accessing source directory: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the check\n",
    "system_ready = check_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4148591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_sliding_window(video_path, save_root_dir):\n",
    "    \"\"\"\n",
    "    Splits video into multiple overlapping clips (Bags of Instances).\n",
    "    Returns the number of clips created.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return 0\n",
    "\n",
    "    # Read all frames into memory (Fastest for 3080Ti systems with high RAM)\n",
    "    frames_buffer = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Resize immediately to save RAM and Disk space\n",
    "        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "        frames_buffer.append(frame)\n",
    "    cap.release()\n",
    "    \n",
    "    # Safety check: Video too short?\n",
    "    min_needed = (SEQ_LEN - 1) * STRIDE + 1\n",
    "    if len(frames_buffer) < min_needed:\n",
    "        return 0\n",
    "\n",
    "    # --- THE CRITICAL FIX: SLIDING WINDOW LOOP ---\n",
    "    clip_count = 0\n",
    "    \n",
    "    # Start at 0, slide forward by CLIP_STEP (64)\n",
    "    for start_idx in range(0, len(frames_buffer), CLIP_STEP):\n",
    "        \n",
    "        # Calculate indices: [start, start+5, start+10, ... up to 16 frames]\n",
    "        indices = [start_idx + (i * STRIDE) for i in range(SEQ_LEN)]\n",
    "        \n",
    "        # Check if the last frame needed is inside the video\n",
    "        if indices[-1] >= len(frames_buffer):\n",
    "            break\n",
    "            \n",
    "        # Create the Sub-Folder for this Clip\n",
    "        # Example: .../Explosion001/clip_0000/\n",
    "        clip_name = f\"clip_{clip_count:04d}\"\n",
    "        clip_dir = os.path.join(save_root_dir, clip_name)\n",
    "        os.makedirs(clip_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the 16 images\n",
    "        for i, frame_idx in enumerate(indices):\n",
    "            img = frames_buffer[frame_idx]\n",
    "            save_path = os.path.join(clip_dir, f\"img_{i:03d}.jpg\")\n",
    "            cv2.imwrite(save_path, img)\n",
    "            \n",
    "        clip_count += 1\n",
    "        \n",
    "    return clip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19588942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SYSTEM DIAGNOSTICS\n",
      "==================================================\n",
      "‚úÖ GPU DETECTED: NVIDIA GeForce RTX 3080 Ti\n",
      "   Status: Ready for Phase 2 (TimeSformer).\n",
      "   Note: Phase 1 (Frame Extraction) will use CPU/Disk mainly.\n",
      "‚úÖ DATASET FOUND: 15 Classes detected.\n",
      "   Classes: ['Abuse', 'Arrest', 'Arson', 'Assault', 'Burglary', 'Explosion', 'Fighting', 'Normal', 'RoadAccidents', 'Robbery', 'Shooting', 'Shoplifting', 'Splits', 'Stealing', 'Vandalism']\n",
      "\n",
      "==================================================\n",
      "STARTING PHASE 1: SLIDING WINDOW EXTRACTION (WITH METADATA)\n",
      "==================================================\n",
      "\n",
      "üìÇ Processing Class: Abuse (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3f0d3662384912ace6d49db5835e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Abuse:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Arrest (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9d4422b14b4a5a81ab89f28953bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Arrest:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Arson (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a498d7d803742d99196f8e3f406f70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Arson:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Assault (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2b5408a49f49b4ad160b041093d4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Assault:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Burglary (100 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9f7bc7c43240babae78932044013ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Burglary:   0%|          | 0/100 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Explosion (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78ea5b8fc2349d9a715b5009e3ab6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Explosion:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Fighting (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23c4f47a3e14c8f9f5c05b0ae0a9696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Fighting:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Normal (950 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2cf3242bcd420cb58ae61be46f479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Normal:   0%|          | 0/950 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: RoadAccidents (150 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7554bc281f084dfb8c7cff988afc2f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting RoadAccidents:   0%|          | 0/150 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Robbery (150 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3341759e656443ff9b2f01498184eee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Robbery:   0%|          | 0/150 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Shooting (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405a2b7262924eb4b55fca246fd813b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Shooting:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Shoplifting (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6127243294e046edadcc777dac57601f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Shoplifting:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Splits (0 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23247484f6774c71beba17a4b9c8d479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Splits: 0vid [00:00, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Stealing (100 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937823bfa81b47edbd8ec7f944712596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Stealing:   0%|          | 0/100 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing Class: Vandalism (50 videos)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b17576914b644bca86af0bf94239db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Vandalism:   0%|          | 0/50 [00:00<?, ?vid/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "‚úÖ PHASE 1 COMPLETE\n",
      "üìÑ Metadata saved to: C:\\UCF_video_dataset\\Processed_Clips\\dataset_metadata.json\n",
      "üìä Total Videos Processed: 1900\n",
      "Next Step: Load 'dataset_metadata.json' in Phase 2.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json # Make sure this is imported\n",
    "\n",
    "def main():\n",
    "    if not check_system():\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING PHASE 1: SLIDING WINDOW EXTRACTION (WITH METADATA)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    classes = os.listdir(SOURCE_DIR)\n",
    "    \n",
    "    # --- METADATA STORAGE ---\n",
    "    # This list will track every video we process\n",
    "    dataset_metadata = [] \n",
    "\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(SOURCE_DIR, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "            \n",
    "        # Create Class Output Directory\n",
    "        class_out_dir = os.path.join(OUTPUT_DIR, class_name)\n",
    "        os.makedirs(class_out_dir, exist_ok=True)\n",
    "        \n",
    "        # Get list of videos\n",
    "        videos = [f for f in os.listdir(class_path) if f.lower().endswith(('.mp4', '.avi', '.mkv'))]\n",
    "        \n",
    "        print(f\"\\nüìÇ Processing Class: {class_name} ({len(videos)} videos)\")\n",
    "        \n",
    "        for vid_file in tqdm(videos, desc=f\"Extracting {class_name}\", unit=\"vid\"):\n",
    "            \n",
    "            video_path = os.path.join(class_path, vid_file)\n",
    "            video_name = os.path.splitext(vid_file)[0]\n",
    "            \n",
    "            # Output path: .../Processed_Clips/Explosion/Explosion001\n",
    "            video_out_dir = os.path.join(class_out_dir, video_name)\n",
    "            \n",
    "            # 1. RUN EXTRACTION\n",
    "            n_clips = 0\n",
    "            \n",
    "            # Check if already processed to save time\n",
    "            if os.path.exists(video_out_dir) and len(os.listdir(video_out_dir)) > 0:\n",
    "                n_clips = len(os.listdir(video_out_dir)) # Count existing folders\n",
    "            else:\n",
    "                try:\n",
    "                    n_clips = process_video_sliding_window(video_path, video_out_dir)\n",
    "                    if n_clips == 0 and os.path.exists(video_out_dir):\n",
    "                        shutil.rmtree(video_out_dir) # Delete empty folders\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error extracting {vid_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # 2. LOG METADATA (Crucial for Phase 2)\n",
    "            if n_clips > 0:\n",
    "                record = {\n",
    "                    \"video_name\": video_name,\n",
    "                    \"class_name\": class_name,\n",
    "                    \"num_clips\": n_clips,\n",
    "                    \"clips_path\": video_out_dir,\n",
    "                    \"original_video_path\": video_path\n",
    "                }\n",
    "                dataset_metadata.append(record)\n",
    "\n",
    "    # --- SAVE METADATA FILE ---\n",
    "    metadata_path = os.path.join(OUTPUT_DIR, \"dataset_metadata.json\")\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚úÖ PHASE 1 COMPLETE\")\n",
    "    print(f\"üìÑ Metadata saved to: {metadata_path}\")\n",
    "    print(f\"üìä Total Videos Processed: {len(dataset_metadata)}\")\n",
    "    print(\"Next Step: Load 'dataset_metadata.json' in Phase 2.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
